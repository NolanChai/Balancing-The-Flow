I’m not sure if there is an easy way to exclude specific file types or extensions, but you could try using the -name and -iname options in combination with the grep command. For example:

find / -type f -iname "*.log" -exec grep -H “suricata” {} +

This would search for all log files (files ending in .log) on the system, then run the grep command within each file to find occurrences of “suricata”. However, this approach may still be resource-intensive and slow if you have a large number of log files. You may want to consider using an alternate method like the journalctl or tail commands, which provide more specific filtering options for searching through system logs.

I’m not sure why you would need to search only for “*.log” files specifically in your case, but I can see how that could be useful if you are trying to find a specific type of log file that is being generated by Suricata. You may want to review the available options and settings for Suricata on your system to determine what types of logs are being generated and where they are stored.

The grep command with the -name option should only search within files matching the specified name, so you shouldn’t find any results from files related to suricata.yaml unless they also match the criteria for a “*.log” file. However, as I mentioned before, this approach may not be as efficient if there are many log files on your system.

The use of -iname should have the same effect as using the -name option, but it will search within files with names that contain the specified string instead of only those matching a specific name exactly. This could make things slower and less efficient because more files would need to be examined before any matches were found.

If you are still having trouble finding logs related to Suricata with this approach, I recommend consulting the documentation or configuration files for Suricata on your system to determine where logs are being generated and what types of log entries they contain. You may also want to try using a different tool like journalctl or tail instead if you need more advanced filtering options.

good. at least it doesn’t output “suricata” in any other file or folder except for .log files. that was the main goal. thank you very much for your time and support.

You can use a pipe like | to send the result to another command, grep is able to do that and there are some other commands that also allow you to read from stdin. I am not sure if that's exactly what you want but it should be an option for you.

`find -name 'suricata.log'` will search your current directory and all subdirectories, which is probably what you're looking for (if the command returned lots of results from `/var/log`, it's because it was in a different working directory).

You can also use `grep` to search within a file for a specific string. The syntax might be something like:

\begin{code}
grep -r 'string' <directory>
\end{code}

The "--line-buffered" switch will force find to output one result for each line. The grep command will just count the occurances of suricata in the log files that it finds, and pipe that into uniq -c (which counts unique lines) which will then show you how many times 'suricata' appears in each log file.

Comment: So, if i add all the "| sort | uniq" commands, after this command "sudo find / -type f -name "*.log" -exec grep --line-buffered -H "suricata" {} +", it will show me only the occurences of the string 'suricata' in each log file?

Comment: @user2567314 Yes, that should work. If you find a better way to do this I would love to see your answer on my question!

This is a warning for the user that the file is not world readable, but it will still work as expected. The log file is created with the permissions of the owner (in this case you) so it's a security feature to ensure you can only see your own logs and not anyone else's.

It means that you don't have a user named 1000 (or the like) on your system, and thus it can not be authenticated as a valid account. You need to create an account with the name that you want to use. Also, I am curious if you tried the other examples? The first is a command line, which should work for you if your system allows it (but in general you are unlikely to have an SSH connection from your terminal to your phone).
The second is what you wanted, and that should be working perfectly for you.

It is because your home directory is `/home/susan`. Your user folder in `/root` is different. You could use `chdir` command to change current directory to the one you want:
```bash
chdir /root/user_folder
```

> The GVFS component was disabled on your system as a workaround for this issue: https://bugzilla.redhat.com/show_bug.cgi?id=962389 . This bug is related to a race condition in the ICE daemon that causes it to lock files forever, and there isn't yet a workaround for GNOME or KDE users with this issue.

The solution is in your question! There are NO mounted File Systems! It's probably a good idea to get used with mounting File systems from the terminal. With that said, there are a few options you can try on a Ubuntu based system. I would use the "Mount" command and the "Unmount" command to make things happen. You will need to know the device name (you should be able to figure out what it is by searching for the drive letter).

`# mount /dev/sdb1 /mnt/drive`

or

`# mount /dev/sdc2 /mnt/disk`

I would recommend using something like GParted instead of the above, but it will be faster to get things working.

Once you have a mounted drive in place, the "Unmount" command is:

`# umount /dev/sdb1`