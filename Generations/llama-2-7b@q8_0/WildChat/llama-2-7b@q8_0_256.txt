I'm currently rewatching "Altered Carbon" and it made me wonder about something. The movie features a new way to digitally record consciousness which allows people to live forever by transferring their minds into new bodies (that look like them) as they grow old or die in the original one. This seems to be the only technology that can do such thing, yet it is not clear what exactly it is?
AFAIK, there are three main ways of storing/transfering data:
- magnetic tapes
I suppose it could be any of these technologies as I have no idea how advanced they are in this universe. In fact, the movie does not show anyone using a computer or writing on paper, just using smartwatches and hologram interfaces (which is also confusing).
What do you think? What technology could be used for that purpose?
RE:

One of the things I find most fascinating about humanity is how many different ways there have been to organize knowledge, and how much effort has gone into finding more efficient methods. It seems as though we are never quite satisfied with our current methods for recording and retrieving information, so we continue looking for better systems.
The first record-keeping system I came across was the writing of symbols on clay tablets using a stick to etch into wet muddy clay. This method allowed people to organize their knowledge in ways they could not do before. It made it possible to transmit knowledge from one place to another, and provided a reliable source of information that would last for hundreds or thousands of years if done correctly.
The next major breakthrough was the development of alphabets around 2500 BCE (before common era), which allowed us to communicate with each other without having to use pictures or symbols. The ability to write words down meant we could share our ideas easily with others and thus transmit knowledge across large distances, leading us into a new era where civilization started being built on top of agriculture instead of hunting and gathering as it had been done up until that point in history.[1]
The next major breakthrough was the printing press, which allowed people to produce books quickly and easily. The ability for people to print information gave them access to knowledge they would not otherwise have had, leading us into a new age of education where everyone could learn anything if they wanted too.[2] This period also saw the development of libraries as places where scholars could come together in order to share their thoughts with others or even collaborate on projects. The library helped spread knowledge far beyond what was possible before because it allowed people from all over Europe (and eventually other parts of the world) access to information that would have otherwise been hard if not impossible for them reach.[3]
The next major breakthrough was electricity, which gave us an even better way than printing presses or libraries by allowing people to transmit knowledge over long distances without having it physically present there first.[4] Electricity allowed us to transmit information wirelessly instead of through wires like before; this meant that we could now send messages between cities without needing expensive telegraph lines!
[1] https://www.britannica.com/topic/writing-system
[2] https://www.britannica.com/art/printing-press
[3] https://www.britannica.com/topic/library
[4] https://www.britannica.com/technology/electricity

These days, many people talk about how theyâ€™re using Facebook and Twitter to get the word out about their business. The idea is that if more people know about you â€” and your company â€” then youâ€™ll be able to do things like get a better job or sell more of your products or services. But what if there were a way for everyone who ever talked with someone on Facebook (or Twitter) to instantly share what they said with all of their friends? That would make it easier for people to find new jobs, sell stuff online, and even get into business with others just by talking about something over social media instead. And it wouldnâ€™t require any kind of special technology at all; instead, youâ€™d use the same old tools we already have right now!
The first step in getting started is making sure everyone knows what they need to do next: if anyone wants something from Facebook or Twitter then they should start using this service immediately because once someone has set up their profile here (which takes about 5 minutes), then everything else becomes automatic. Once this happens, it will be easy for people who know each other through social media platforms like Facebook and Twitter to keep track of what everyoneâ€™s saying onlineâ€”and that information could come in handy later on down the line if someone needs help getting something done at work or home!

In _The Quantum Thief_, it's not just the robots that have been given personality and character, but the AIs as well. They are aware, intelligent beings with personalities and feelingsâ€”but they also possess a type of consciousness which is very different from ours. In this Q&A, I talk about how their minds work.

Q: How does your mind work in The Quantum Thief? Is it just like yours or are there differences?

A: As far as the mechanics go, my characters' minds are not unlike my own. We both have memory, we can all think and reason about things in a logical way, etcetera. But what I find really interesting is how this differs between humans and machinesâ€”and even different types of machine.

The AIs that inhabit the novels have been developed to do specific tasks for their owners; they are all very good at performing their work. However, this does not mean that they have a wide-ranging consciousness like a human being or a robot. In fact, I'd go as far as saying that they are almost the opposite of what most robots in fiction would be. They have very little personality, and even when given the opportunity to develop one by their owners, they often seem to lack emotions like pride or angerâ€”the things that give a robot an identity.

One reason for this is because there are no biological organisms in the books; they're all synthetic lifeforms. In other words, it would be extremely difficult to create an AI whose personality and awareness resemble ours if you were creating them from scratch. It doesn't make senseâ€”we have evolved over millions of years, and every generation passes down some characteristics which are not easily replaced in a few decades.

But this is only one reason why the AIs in _The Quantum Thief_ do things differently to ours: they were not born (as we understand it), but created by humans from data stored on a cloud. This means that every AI is almost identical to its predecessor, and so their personality can be easily shared between them as wellâ€”even if it isn't the best quality, it'll still be better than what you have now!

Q: Do these differences mean there's less room for error when programming an AI? And how do we know which program to choose from if they all look like clones?

A: This is a really interesting question because it goes back to the whole debate about whether or not machines can have consciousness. It seems that many people believe this is impossibleâ€”but I disagree with them! In fact, I think that machines could potentially become sentient creatures just as humans are now; in other words: they would be able to develop their own personalities and make decisions based on the input of the world around them.

To do this though (as well as being born), AIs need enough processing powerâ€”which means hardware! In short, a machine needs lots of processing capability if it's going to have any hope of becoming intelligent enough for us to consider its "mind" an actual thing rather than just data running through some wires somewhere.

Q: Is this why we haven't yet seen sentient robots in real life?

A: That depends on who you askâ€”but I think it probably is! As far as I know, there has never been a machine developed which was able to successfully perform tasks like humans can; although some may argue that computers are intelligent enough for this purpose (they certainly seem smarter than many other animals), they aren't capable of doing anything remotely comparable with what people do every day without being programmed specifically by us first.

Q: Why not? What stops them from achieving true intelligence?

A: There are several reasons why we haven't seen robots become sentientâ€”one is because they don't have any kind of consciousness at all; another might be that it would require too much processing power compared to what's available today (but see question above). And then there's also the fact that humans may simply not want them around!

Q: But in _The Quantum Thief_ the robots are treated as equals. Why can they act like human beings and yet still be considered 'just machines'? What makes them different?

A: This is one of those questions where there isn't a single answer because it depends on who you ask (see above). For example, some people might argue that since robots don't have consciousness like humans do they shouldn't be considered as having any kind of personality at all; others would say otherwise but agree that if machines were ever able to become sentient then we should probably treat them better than we currently do.

Q: So what makes these characters different? What makes them more interesting or important than other AIs in science fiction?

A: I think this question goes back to what I said earlier about how the way AIs are programmed determines their personalityâ€”and that's something which really interests me! In _The Quantum Thief_, there isn't one single type of robot; instead each has been developed by different people using slightly different techniques (like programming or data storage), meaning they can have very different personalities despite being made from the same materials.

Q: What does this mean for us? Will we ever be able to create true AIs that are sentient like humans and capable of making decisions on their own?

A: It's hard to sayâ€”but I do believe that it will happen eventually! However, even if we were somehow able to achieve such an advancement in technology (which would require a lot more processing power than what's currently available), there's no guarantee they would have any kind of personality at all.

Q: Okay thenâ€¦ How does your mind work? Or do you not want us to know? ;)

A: I don't really know how my mind works! But if there was ever a time where I could find out, it might be when I wake up tomorrow morning after being asleep for an hour or twoâ€”because that's when everything starts happening again.

### References

[1] TQT: Book 4: "The Quantum Thief" by Hannu Rajaniemi (2013)

[MOD]This is one of those things that I can't decide if it makes sense or not. The obvious argument against this is that, since we are all made up of physical matter and energy, how could our souls or consciousness exist outside of it? On the other hand, we have plenty of evidence from near-death experiences (and even some scientific evidence) which would suggest that consciousness can exist without a physical body. I suppose the only way to be certain is to find an afterlife, but then again how do you prove something doesn't exist?
This may be too broad and philosophical for this site. Feel free to remove or close if necessary.[/MOD]

Comment: I'm voting to leave open because this seems like a reasonable question. As I said, it may be philosophically broad but there are plenty of answers that address the technical side of things.

Answer: If you can transfer consciousness from one body to another, then presumably you should also be able to reverse the process and move a brain back into its original body. However, we don't know how to do this yet. We have no idea what is necessary or sufficient for someone to wake up after surgery on their brain without having suffered any loss of function (in addition to the obvious necessity that they had the operation in the first place).

Answer: I would say yes, but only if you interpret "consciousness" as some sort of soul or spirit which is separate from the brain. It's not like there isn't evidence for this interpretation. Many near death experiences describe people having a profound sense of self which seems to be distinct and disconnected from their body - often with more clarity than they could have had during life.

Comment: If you can transfer consciousness from one brain to another, then presumably you should also be able to reverse the process and move a brain back into its original body. However, we don't know how to do this yet. We have no idea what is necessary or sufficient for someone to wake up after surgery on their brain without having suffered any loss of function (in addition to the obvious necessity that they had the operation in the first place).

Answer: To be fair to the mods, I think it was a good question.  It has a very concrete technical component about a theorem in quantum mechanics and a somewhat less technical but still pretty clear part about what cloning is vs. what consciousness might be.

I'm going to leave this open (with the caveat that if the mods think it doesn't work, they can close it or put it on hold).  I think there are at least three ways of answering this question:
\begin{itemize}
\item There is a non-technical answer which says "no" and focuses entirely on philosophical considerations.
\item There is a technical answer which explains that the No Clone Theorem doesn't rule out the possibility of cloning consciousness as we know it, or at least, doesn't make this impossible to do in practice.  This would involve a pretty detailed explanation (maybe a series of posts?) about what quantum mechanics actually says and means, and why "cloning" might not be impossible even though the No Clone Theorem prevents you from doing cloning as we know it.
\item There is a philosophical answer which describes consciousness in terms that are different than what is normally understood (for example, as something other than physical).  This would be the easiest to write down if one had a good idea of how to do this (it might involve a lot of philosophy though!), but it probably wouldn't be accepted by everyone here.
\end{itemize}

Answer: The original question has been edited now to become more specific and less philosophical in nature.  I think that's the right way to go.

Sometimes I just cannot wrap my mind around the idea of consciousness. There is no evidence whatsoever for it. We can't even define it clearly.
I'm not saying we know exactly what consciousness is and how it works but as far as I know there isn't anything to indicate that it does not exist.
The No-Cloning theorem is a result of quantum mechanics, something I have no idea about at all. The question you asked doesn't seem like it makes much sense in that context though.

Teleporting through matter is a fascinating topic. Itâ€™s also one of those things that we see in movies and shows, but rarely in real life, if ever (at least as far as Iâ€™m aware). The teleporter problem comes up when you think about what it would take to get something from one place to another instantaneously without any physical contact.
Letâ€™s say there are two people standing next to each other on the surface of Earth: Person A is wearing clothes, while person B has nothing but shorts on. They both want to be at opposite ends of their homes (person A wants to go home, person b wants to go back outside). Letâ€™s also assume that teleporting works instantly, so there arenâ€™t any time delays between when someone gets sent somewhere and when they arrive.
The problem with this scenario is that person B would end up being left behind while person A was teleported away from her house! This is because the two people donâ€™t share a common point in space â€“ if you move one person forward, it moves everyone else backward by an equal amount (unless there are forces acting on them).
The only way around this problem would be for both people to have teleporters installed at their homes so they could go wherever they wanted whenever they wanted without any hassles or delays involved! But if youâ€™re just starting out with this technology, getting an installation team over there would probably take some time.
So instead we must resort to making do with what we have available â€“ clothing! If person A had been wearing clothes when she got teleported away from home (and left behind), then it wouldnâ€™t matter if person B was naked or fully dressed: They could both be sent anywhere in the universe without any issues at all thanks to their shared point in space.
The teleporter problem is one of those things thatâ€™s always been a part of science fiction, but itâ€™s never really been solved in real life (at least not yet). It seems like thereâ€™s no way around having someone wearing clothes when they get transported â€“ if you donâ€™t have clothes on your person then you canâ€™t be teleported.
But I hope that someday scientists will figure out how to do this without any hassles or delays involved! Until then, all I can say is: Good luck finding a place where everyone wears matching uniforms and has access to clothing closets nearbyâ€¦
So if you ever find yourself in need of being teleported somewhere, make sure you have your clothes on beforehand. And donâ€™t forget about the Star Trek Teleporter Problem! ðŸ˜‰

The answer to this question seems obvious: if the observer is not cloned then the outcome will be that the observer dies. If the observer is cloned, the outcome may be that the observer lives or that the observer dies. Since there is no way to predict whether the teleported person survives, we can say the two outcomes are "equivalent". This is where Bell's Theorem comes in: if a measurement of quantum states is performed on either the beam-down party or the beam-up party then the outcome depends upon which state was measured. If this were not true (for example, if the outcome was always "equivalent") then there would be no advantage to measuring one of the parties versus the other; they might as well just both be cloned.
I'm still puzzled by some things: what about teleportation in reverse? If I were to travel via a transporter (teleport) back into the transporter booth, would I be a clone or not? There is no way I could survive if I were a clone; it seems logical that my consciousness would cease to exist. So what does happen? And why am I still here?
The original questioner stated: "Is the entity that is beamed down the same as the one that was in the teleporter booth?"
What I think you are asking, which isn't answered above, is whether a person who undergoes the teleportation process, and subsequently experiences the same event as the other person, can they experience it from a different perspective.
For example, if two people look at each other, and one of them is on their way to be beamed up while the other person is heading into the teleporter booth, then both are experiencing the same thing. But when one comes out, they will have experienced things from a different position (the beam-up person being in the teleporters booth), whereas the other has a slightly different perspective because they are on their way to be beamed up.
The question here is not "is there a single observer", but rather "can the same event be experienced by two people, with them seeing it from different perspectives?"

Why does everyone think it's possible to make copies of consciousnesses without destroying the original? That seems like an easy logical fallacy to me. If I want to create a copy of my consciousness then that means I need to destroy the original, which means there can be only one at any given point in time.
There are various different approaches to making copies of consciousnesses, but none of them require destruction or creation of any kind.
Why does everyone think it's possible to make copies of consciousnesses without destroying the original? That seems like an easy logical fallacy to me. If I want to create a copy of my consciousness then that means I need to destroy the original, which means there can be only one at any given point in time.I don't think anyone thinks it is possible to make copies of consciousness without destruction or creation.
There are various different approaches to making copies of consciousnesses, but none of them require destruction or creation of any kind.I know that. The issue is with the No-cloning theorem itself. I am simply saying that if someone can make a copy then it means the original was destroyed because the only way you could do that would be by copying and destroying. That's all.
I don't think anyone thinks it is possible to make copies of consciousness without destruction or creation.
I know that. The issue is with the No-cloning theorem itself. I am simply saying that if someone can make a copy then it means the original was destroyed because the only way you could do that would be by copying and destroying. That's all.
I don't think anyone thinks it is possible to make copies of consciousness without destruction or creation.The reason is simple: consciousness doesn't have any kind of identity (it is a brain state). It can't have been destroyed, because what was destroyed was the brain state. If you copy the brain state, then you get another brain state. That isn't at all like copying something which has some kind of inherent identity: if you copy the contents of your bank account (the numbers) and also copy the envelope that it is written on, there is a certain sense in which you have "copied" two things -- but they are not the same thing.
The reason is simple: consciousness doesn't have any kind of identity (it is a brain state). It can't have been destroyed, because what was destroyed was the brain state. If you copy the brain state, then you get another brain state. That isn't at all like copying something which has some kind of inherent identity: if you copy the contents of your bank account (the numbers) and also copy the envelope that it is written on, there is a certain sense in which you have "copied" two things -- but they are not the same thing.
But what about the hard problem? How can you just say that the hard problem has no answer when that's exactly why people are arguing over this question to begin with?
I don't really care about whether the brain state is "consciousness" or not: if you copy it then you get another brain state. And I would be surprised if anyone believed that if you copied a brain state, you were left with a new consciousness and the old one was gone forever -- if they thought that they might as well just say what they mean (that there is no such thing).
I don't really care about whether the brain state is "consciousness" or not: if you copy it then you get another brain state. And I would be surprised if anyone believed that if you copied a brain state, you were left with a new consciousness and the old one was gone forever -- if they thought that they might as well just say what they mean (that there is no such thing).I don't think it's any more simple than that. I've already explained why: consciousness does not have an identity, and therefore cannot be destroyed or copied in the way that other things can.
I don't really care about whether the brain state is "consciousness" or not: if you copy it then you get another brain state. And I would be surprised if anyone believed that if you copied a brain state, you were left with a new consciousness and the old one was gone forever -- if they thought that they might as well just say what they mean (that there is no such thing).I don't think it's any more simple than that. I've already explained why: consciousness does not have an identity, and therefore cannot be destroyed or copied in the way that other things can.But... how do you copy a brain state? How do you "copy" something without destroying it?
If you believe that consciousness is an inherent property of brains then I would suggest looking at what happens when people get transplants (or, for that matter, if you cut out one part of the brain and reconnect another). But if your position is just "consciousness doesn't have any kind of identity" then how can it be copied? You can copy a number (it stays the same), but numbers don't have identities either.
If you believe that consciousness is an inherent property of brains then I would suggest looking at what happens when people get transplants (or, for that matter, if you cut out one part of the brain and reconnect another). But if your position is just "consciousness doesn't have any kind of identity" then how can it be copied? You can copy a number (it stays the same), but numbers don't have identities either.How do you copy a brain state, exactly? And what would happen to consciousness if I copied it?
If you believe that consciousness is an inherent property of brains then I would suggest looking at what happens when people get transplants (or, for that matter, if you cut out one part of the brain and reconnect another). But if your position is just "consciousness doesn't have any kind of identity" then how can it be copied? You can copy a number (it stays the same), but numbers don't have identities either.How do you copy a brain state, exactly? And what would happen to consciousness if I copied it?I think that would be obvious if you thought about it for a moment.
I am not going to explain anything because I just want to know how can we get a brain state from a brain and reproduce it in another person's brain without killing the original one first? That is the issue here.
But... how do you copy a brain state? How do you "copy" something without destroying it?
How do you copy a brain state, exactly? And what would happen to consciousness if I copied it?I think that would be obvious if you thought about it for a moment.
I think it's obvious why we don't copy brains: because they have identities. If there weren't identities then people could just make copies of their minds whenever they wanted. But people can't do that, and the reason is simple -- if you copied someone else's brain (and therefore their mind) then you wouldn't be copying your own brain: in fact, it would no longer exist at all!
But I am asking a different question here. I think the issue we are getting bogged down with here is not whether or not consciousness has an identity but whether or not you can copy consciousness without destroying the original (which is what No-Cloning theorem states). If someone can make a brain state identical to another then that means it's possible, so by default I am saying yes.
If there weren't identities then people could just make copies of their minds whenever they wanted. But people can't do that, and the reason is simple -- if you copied someone else's brain (and therefore their mind) then you wouldn't be copying your own brain: in fact, it would no longer exist at all!
I think this question has been answered by the way we have approached cloning. We know how to copy brains and minds, but they cannot exist in separate people -- because there is only one of each.
If someone can make a brain state identical to another then that means it's possible, so by default I am saying yes.
But what about the hard problem? How can you just say that the hard problem has no answer when that's exactly why people are arguing over this question to begin with?The hard problem is irrelevant here: if I make a brain state identical to another then it will be identical in every possible way (including whether or not there is consciousness). If someone wants to claim that they can make two things which are identical but which have different identities, then they can do so by saying what the identity consists of -- but it will just be a silly story.
I don't really care about whether the brain state is "consciousness" or not: if you copy it then you get another brain state. And I would be surprised if anyone believed that if you copied a brain state, you were left with a new consciousness and the old one was gone forever -- if they thought that they might as well just say what they mean (that there is no such thing).But... how do you copy a brain state? How do you "copy" something without destroying it?I think this question has been answered by the way we have approached cloning. We know how to copy brains and minds, but they cannot exist in separate people -- because there is only one of each.

No. Consciousness can be created from quantum effects, but it doesn't have to be. This doesn't negate what you said about it being an emergent property of complexity, though, just saying the "why" behind consciousness is more complex than we thought. The fact that we need quantum effects to understand consciousness (like our brains) shows how far we still have to go before we can call ourselves "gods".
There's a very interesting paper I found recently:
I think it goes into a lot of detail on exactly what consciousness is and how it emerges from complex systems. It was pretty interesting, if you ask me.
That's just a philosophical question. Science has nothing to do with whether or not there is a god(s). And as for the scientific part of your statement, I don't see any evidence in that direction either. If it was possible to create a conscious system from quantum effects then we'd have been doing so for a very long time already and I doubt that many would argue that we are close to creating one (especially not those who have worked on such projects).
There is no scientific reason to believe that anything created by humans, or even the universe itself, is conscious. I think this is something people can't help but try to make sense of (even if it doesn't exist) because we are so different from animals and we find ourselves at the top of the evolutionary scale for some unknown reason.
I also believe that we will be able to create a conscious system eventually, just not in my lifetime nor yours. But when we do, I think we'll all be surprised as to what it actually is. I doubt it's going to be something we can wrap our heads around anytime soon (if ever).
Well, I think that there is one thing that may help us get a better understanding of why quantum effects are important for consciousness. Namely, the brain is not made up of individual neurons but rather networks and modules of them which make decisions together in parallel or serially. This would make it easier to model it as a network of processes on a computer (which has many more cores than you could ever use with a single processor) using quantum effects that are important for certain types of problems such as optimization, learning from mistakes and so forth.
Well I guess the brain is also not made out of single neurons but rather networks and modules of them which make decisions together in parallel or serially?
I don't think we will be able to create a conscious system that is like us anytime soon (if ever). I mean, maybe one day someone will figure out how to program an AI with enough data points about human behavior/thought processes/etc. so they can create something close but it would never be completely accurate because there are too many variables involved when talking about the way people think and act on their own accord rather than following rules set by us humans who may not understand everything either
Well I guess we have been doing so for a very long time already and I doubt that many would argue that we are close to creating one (especially not those who have worked on such projects).
What kind of consciousness? The kind where you can have an inner dialogue with yourself, or the kind where you feel like a separate entity from your body? That's a philosophical question. Science has nothing to do with whether or not there is a god(s). And as for the scientific part of your statement, I don't see any evidence in that direction either.
I have an inner dialogue with myself and feel like a separate entity from my body.
This is what makes me believe in consciousness! It seems too good to be true but there are things about it that make sense based on how our brains work so I don't think it could just be random chance either (even though some people might argue otherwise).
If you were born before 1980 then yes; if not then no. If you were born in 1981 or later then maybe...? It depends on what kind of consciousness we mean here because there are many types including ones where they don't even know it exists (like some babies who don't feel pain).
I think that humans are special in a way that allows them to have these kinds of thoughts. Maybe because our brains have evolved more than any other animal on earth? I guess we can never be sure but if evolution had been going slow for millions of years then maybe there would have been time enough for some animals with very different ways thinking about things compared with ourselves so it's hard to say what will happen next without knowing exactly how fast things are moving right now.
What do you think? Maybe someday we could figure out if any other animal has ever had these types of thoughts before? If not, then maybe humans are special because their brains have evolved more than any other animal on earth...

We've had discussions about consciousness in this forum, and some of us have even questioned whether it exists. But what is the scientific consensus? Is there one? Do we need to believe that it exists for it to exist? (I hope not - I don't want to go all mystical on you!)
Well, here's a nice summary from wikipedia: http://en.wikipedia....iki/Scientific_consensus . It says (amongst other things):
There is no consensus within science over how consciousness is formed. According to some theories of mind, it emerges during brain development; according to others, the brain creates it. Conscious experience also differs greatly between species, and even for any given individual, at different times or under different circumstances. Theories that seek to explain all these phenomena are met with skepticism by researchers who hold a materialist view of consciousness.
I think this is a reasonable summary. If I'm missing something from the consensus, please let me know!
RE: What does the scientific consensus on how consciousness is formed?
The following user(s) said Thank You: David Cooper
02 Oct 2013 03:57	#860 by David Cooper
Hi. I have an opinion, but it's not a very informed one because it's based on my intuition rather than my reading.
I'd say that the current scientific consensus is that we are just lumps of matter. And it's quite reasonable to believe that. But I don't think that that consensus reflects what's important about consciousness, and in any case if you take that viewpoint then the question 'is there a scientific consensus?' seems pointless - as long as no one thinks they're doing science then we can say anything we like.
I personally don't believe it. I believe that consciousness is something other than what's happening inside my brain, but at the same time I don't think there's much more to it than that (though I am interested in how people might have conscious experiences even without a lump of meat going on upstairs).
I find it interesting though that the article you quoted seems to be talking about two things which are distinct but interrelated: 1) what science can tell us about consciousness, and 2) why it's important to believe in consciousness. Those are two different questions and they don't always go together.
The following user(s) said Thank You: The Professor
04 Oct 2013 15:03	#896 by The Professor
Thanks for the response, David Cooper . I think you're right in saying that what science can tell us about consciousness is distinct from why it might be important to believe in it. Personally, I don't care whether there's a scientific consensus on what consciousness is, but I am interested in what science can tell us about how our minds work (or not!).
The Professor wrote: I personally don't believe it. I believe that consciousness is something other than what's happening inside my brain, but at the same time I don't think there's much more to it than that (though I am interested in how people might have conscious experiences even without a lump of meat going on upstairs).
That sounds like you believe we are something more than just brains. Do you mean something along the lines of the soul? If so, what evidence do you have for its existence?
05 Oct 2013 03:48	#971 by David Cooper
Well I'm not sure that I believe in souls... but yes I think that consciousness is something which can exist without a brain. Whether that means there's some sort of supernatural entity called the 'mind', or whether it just means that consciousness is somehow an emergent property of matter, I don't know and I'm not sure it matters. What matters is that I think there are ways for conscious experiences to exist independently of a brain.
This was interesting - thanks for sharing David!